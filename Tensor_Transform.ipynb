{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "lkJH3OxHA3cP"
      ],
      "mount_file_id": "1brwRM0pNfjqfi3MgWZgT1O7gB2xbupqr",
      "authorship_tag": "ABX9TyMRc3SDrLZ+5A1tXWOxI0t2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/adwardkim9/comet-hunting/blob/main/Tensor_Transform.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JENK4H7-8ezL"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pathlib\n",
        "import torch\n",
        "import torchvision\n",
        "from astropy.io import fits"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## path_csv"
      ],
      "metadata": {
        "id": "lkJH3OxHA3cP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#예제 파일 읽기\n",
        "train_files = natsort.natsorted(glob.glob('/content/drive/MyDrive/Comet Hunting/Train/cmt*/*.fts'))"
      ],
      "metadata": {
        "id": "GrILug1d1uCA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_files)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vsOKxyGD3YU1",
        "outputId": "83b95b3b-1c4c-4623-99c8-d59e00eb9313"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "24195"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "split_lists = [string.split(', ') for string in train_files]"
      ],
      "metadata": {
        "id": "hHKm1O7K6t0j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "\n",
        "# File path to save the CSV\n",
        "file_path = '/content/drive/MyDrive/Comet Hunting/train_file_path.csv'\n",
        "\n",
        "# Writing data to CSV file\n",
        "with open(file_path, mode='w', newline='') as file:\n",
        "    writer = csv.writer(file)\n",
        "    for sublist in split_lists:\n",
        "        writer.writerow(sublist)\n",
        "\n",
        "# with open(file_path, mode='w', newline='') as file:\n",
        "#     writer = csv.writer(file)\n",
        "#     for path in file_path:\n",
        "#         writer.writerow([path])\n",
        "\n",
        "print(\"Data saved to\", file_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q8osljEX3oKN",
        "outputId": "82cfcbfa-e632-4eef-a416-44059acb9a79"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data saved to /content/drive/MyDrive/Comet Hunting/train_file_path.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import natsort\n",
        "import glob\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "metadata": {
        "id": "4gHqzpFk2OE8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1"
      ],
      "metadata": {
        "id": "4-0BsZ8VA7Bp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "/content/drive/MyDrive/Comet Hunting/Test/10146987/22546251.fts"
      ],
      "metadata": {
        "id": "mKC6R9l02gOD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to load FITS images and normalize them\n",
        "def load_and_normalize_fits_images(folder_path):\n",
        "    image_tensors = []\n",
        "    folder_path = pathlib.Path(folder_path)\n",
        "    for subfolder in folder_path.iterdir():\n",
        "        if subfolder.is_dir() and subfolder.name.startswith(\"cmt\"):\n",
        "            subfolder_num = int(subfolder.name[3:])  # Extract the numeric part from the folder name\n",
        "            if 201 <= subfolder_num <= 300:  # Check if the folder number is within the range\n",
        "                subfolder_images = []\n",
        "                for fits_file in subfolder.iterdir():\n",
        "                    if fits_file.suffix.lower() == '.fts':\n",
        "                        # Load FITS image\n",
        "                        image_data, header = fits.getdata(str(fits_file), header=True)\n",
        "                        # Normalize the image data (you can customize the normalization)\n",
        "                        image_data = image_data / header['EXPTIME']\n",
        "                        normalized_image = (image_data - np.min(image_data)) / (np.max(image_data) - np.min(image_data))\n",
        "                        # Convert to PIL image\n",
        "                        image = Image.fromarray(normalized_image)\n",
        "                        # Convert to tensor\n",
        "                        image_tensor = torch.tensor(np.array(image), dtype=torch.float32)\n",
        "                        subfolder_images.append((fits_file.stem, image_tensor))  # Store file name with tensor\n",
        "                image_tensors.append((subfolder.name, subfolder_images))\n",
        "    return image_tensors\n",
        "\n",
        "# Function to save image tensors\n",
        "def save_image_tensors(image_tensors, save_folder):\n",
        "    for folder_name, subfolder_images in image_tensors:\n",
        "        subfolder_save_folder = f\"{save_folder}/{folder_name}\"\n",
        "        pathlib.Path(subfolder_save_folder).mkdir(parents=True, exist_ok=True)  # Create folder if not exists\n",
        "        for file_name, image_tensor in subfolder_images:\n",
        "            save_path = f\"{subfolder_save_folder}/{file_name}.pt\"\n",
        "            torch.save(image_tensor, save_path)"
      ],
      "metadata": {
        "id": "VITeMlCL8kWh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Path to the train folder\n",
        "train_folder = \"/content/drive/MyDrive/Comet Hunting/Train/\"\n",
        "\n",
        "# Load and normalize FITS images from train folder\n",
        "image_tensors = load_and_normalize_fits_images(train_folder)\n",
        "\n",
        "# Path to save the image tensors\n",
        "save_folder = \"/content/drive/MyDrive/Comet Hunting/Train_image_tensors/\"\n",
        "\n",
        "# Save image tensors\n",
        "save_image_tensors(image_tensors, save_folder)\n",
        "\n",
        "print(\"Train Image tensors saved successfully.\")"
      ],
      "metadata": {
        "id": "fAuW9O90_JKc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f78441dc-a576-48b7-8d31-602378e3c4a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Image tensors saved successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to load FITS images and normalize them\n",
        "def load_and_normalize_fits_images_test(folder_path):\n",
        "    image_tensors = []\n",
        "    folder_path = pathlib.Path(folder_path)\n",
        "    for subfolder in folder_path.iterdir():\n",
        "        if subfolder.is_dir():\n",
        "            subfolder_images = []\n",
        "            for fits_file in subfolder.iterdir():\n",
        "                if fits_file.suffix.lower() == '.fts':\n",
        "                    # Load FITS image\n",
        "                    image_data, header = fits.getdata(str(fits_file), header=True)\n",
        "                    # Normalize the image data (you can customize the normalization)\n",
        "                    image_data = image_data / header['EXPTIME']\n",
        "                    normalized_image = (image_data - np.min(image_data)) / (np.max(image_data) - np.min(image_data))\n",
        "                    # Convert to PIL image\n",
        "                    image = Image.fromarray(normalized_image)\n",
        "                    # Convert to tensor\n",
        "                    image_tensor = torch.tensor(np.array(image), dtype=torch.float32)\n",
        "                    subfolder_images.append((fits_file.stem, image_tensor))  # Store file name with tensor\n",
        "            image_tensors.append((subfolder.name, subfolder_images))\n",
        "    return image_tensors"
      ],
      "metadata": {
        "id": "o5zXPmztDaGI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Path to the test folder\n",
        "test_folder = \"/content/drive/MyDrive/Comet Hunting/Test/\"\n",
        "\n",
        "# Load and normalize FITS images from train-sample folder\n",
        "image_tensors = load_and_normalize_fits_images_test(test_folder)\n",
        "\n",
        "# Path to save the image tensors\n",
        "save_folder = \"/content/drive/MyDrive/Comet Hunting/Test_image_tensors/\"\n",
        "\n",
        "# Save image tensors\n",
        "save_image_tensors(image_tensors, save_folder)\n",
        "\n",
        "print(\"Test Image tensors saved successfully.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367
        },
        "id": "toix9i3l_C1x",
        "outputId": "f40df680-5778-4724-c9c1-f79bda289472"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-0e9848bc42f1>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Load and normalize FITS images from train-sample folder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mimage_tensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_and_normalize_fits_images_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_folder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Path to save the image tensors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-3-c836e62f0017>\u001b[0m in \u001b[0;36mload_and_normalize_fits_images_test\u001b[0;34m(folder_path)\u001b[0m\n\u001b[1;32m     12\u001b[0m                     \u001b[0;31m# Normalize the image data (you can customize the normalization)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m                     \u001b[0mimage_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage_data\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mheader\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'EXPTIME'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m                     \u001b[0mnormalized_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mimage_data\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_data\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m                     \u001b[0;31m# Convert to PIL image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m                     \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnormalized_image\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36m_min_dispatcher\u001b[0;34m(a, axis, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m   2829\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2831\u001b[0;31m def _min_dispatcher(a, axis=None, out=None, keepdims=None, initial=None,\n\u001b[0m\u001b[1;32m   2832\u001b[0m                     where=None):\n\u001b[1;32m   2833\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "import pandas as pd\n",
        "\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, data_paths, label_paths):\n",
        "        self.data_paths = data_paths\n",
        "        self.label_paths = label_paths\n",
        "        self.transform = transforms.Compose([\n",
        "            transforms.ToTensor()\n",
        "        ])\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Load tensor data (x)\n",
        "        x = torch.load(self.data_paths[idx])  # Assuming data_paths contain paths to tensor files\n",
        "\n",
        "        # Load label from CSV file (y)\n",
        "        label_df = pd.read_csv(self.label_paths[idx])\n",
        "        y = label_df['label'].iloc[0]  # Assuming 'label' is the column name containing the label value\n",
        "\n",
        "        return x, y\n"
      ],
      "metadata": {
        "id": "jXP03_aWQrx-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#데이터셋 선언\n",
        "dataset = CustomDataset(data=files, label=label)"
      ],
      "metadata": {
        "id": "xqrOBH-LQzh8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## tensor visualization"
      ],
      "metadata": {
        "id": "1heNWXoyQ3v3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from torchvision import transforms, models\n",
        "from matplotlib import pyplot as plt"
      ],
      "metadata": {
        "id": "vCusFQmyLjld"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Load the tensor file\n",
        "tensor_file_path = \"/content/drive/MyDrive/Comet Hunting/sample_image_tensors/cmt0001/22539952.pt\"\n",
        "image_tensor = torch.load(tensor_file_path)\n",
        "\n",
        "# Visualize the tensor as an image\n",
        "plt.imshow(image_tensor.numpy(), cmap='gray')\n",
        "plt.colorbar()\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "kIgjJxeTLyBu"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}